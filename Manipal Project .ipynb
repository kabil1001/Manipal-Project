{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as mlt\n",
    "import datetime  as dt\n",
    "import os\n",
    "import pandas_profiling as pp\n",
    "from  scipy import stats\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    options = {\n",
    "        'display': {\n",
    "            'max_columns': None,\n",
    "            'max_colwidth': 25,\n",
    "            'expand_frame_repr': False,  # Don't wrap to multiple pages\n",
    "            'max_rows': 30,\n",
    "            'max_seq_items': 50,         # Max length of printed sequence\n",
    "            'precision': 4,\n",
    "            'show_dimensions': False\n",
    "        },\n",
    "        'mode': {\n",
    "            'chained_assignment': None   # Controls SettingWithCopyWarning\n",
    "        }\n",
    "    }\n",
    "    for category,option in options.items():\n",
    "        for opt,value in option.items():\n",
    "            pd.set_option(f'{category}.{opt}',value)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    start()\n",
    "    del start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1  = pd.read_csv(\"C:/Users/kxj133/Downloads/Waterpump_indep_var.csv\")\n",
    "data_2  = pd.read_csv(\"C:/Users/kxj133/Downloads/Waterpump_dep_var.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the target variable in the dataframe\n",
    "data =  pd.merge(data_1,data_2,on = \"id\")\n",
    "\n",
    "## Changing the target variable\n",
    "status_group = data['status_group'].unique().tolist()\n",
    "status_group\n",
    "status_group.remove(\"functional needs repair\")\n",
    "\n",
    "\"\"\"Labelling the Functional and non- functional class as func_Non_func label to make the problem simple since \n",
    "our intention is to find the water pump which is functioning but requires repair \"\"\"\n",
    "\n",
    "data[\"status_group\"] = data[\"status_group\"].apply(lambda x : \"func_Non_func\" if x in status_group else x)\n",
    "\n",
    "final_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date_recorded'] = pd.to_datetime(data['date_recorded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description for the features in the dataset\n",
    "\n",
    "1.  amount_tsh - Total static head (amount water available to waterpoint)\n",
    "2.  date_recorded - The date the row was entered\n",
    "3.  funder - Who funded the well\n",
    "4.  gps_height - Altitude of the well\n",
    "5.  installer - Organization that installed the well\n",
    "6.  longitude - GPS coordinate\n",
    "7.  latitude - GPS coordinate\n",
    "8.  wpt_name - Name of the waterpoint if there is one\n",
    "9.  num_private -\n",
    "10. basin - Geographic water basin\n",
    "11. subvillage - Geographic location\n",
    "12. region - Geographic location\n",
    "13. region_code - Geographic location (coded)\n",
    "14. district_code - Geographic location (coded)\n",
    "15. lga - Geographic location\n",
    "16. ward - Geographic location\n",
    "17. population - Population around the well\n",
    "18. public_meeting - True/False\n",
    "19. recorded_by - Group entering this row of data\n",
    "20. scheme_management - Who operates the waterpoint\n",
    "21. scheme_name - Who operates the waterpoint\n",
    "22. permit - If the waterpoint is permitted\n",
    "23. construction_year - Year the waterpoint was constructed\n",
    "24. extraction_type - The kind of extraction the waterpoint uses\n",
    "25. extraction_type_group - The kind of extraction the waterpoint uses\n",
    "26. extraction_type_class - The kind of extraction the waterpoint uses\n",
    "27. management - How the waterpoint is managed\n",
    "28. management_group - How the waterpoint is managed\n",
    "29. payment - What the water costs\n",
    "30. payment_type - What the water costs\n",
    "31. water_quality - The quality of the water\n",
    "32. quality_group - The quality of the water\n",
    "33. quantity - The quantity of water\n",
    "34. quantity_group - The quantity of water\n",
    "35. source - The source of the water\n",
    "36. source_type - The source of the water\n",
    "37. source_class - The source of the water\n",
    "38. waterpoint_type - The kind of waterpoint\n",
    "39. waterpoint_type_group - The kind of waterpoint\n",
    "40. status_group - functional status of the pump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data.nlargest(10000,'gps_height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_Non_func_prop = data[data['status_group'] == \"func_Non_func\"].shape[0]/data.shape[0]\n",
    "functional_needs_repair_prop = 1- func_Non_func_prop\n",
    "print(func_Non_func_prop)\n",
    "print(functional_needs_repair_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class proportion\n",
    "        we have 92 percentange of func_Non_func_prop and 7 percentage of Functional_needs_repair_prop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catog(series):\n",
    "    unique_count = series.nunique()\n",
    "    length_count = len(series)\n",
    "    if pd.api.types.is_int64_dtype(series):\n",
    "        return 'numerical'\n",
    "    elif pd.api.types.is_datetime64_dtype(series):\n",
    "        return 'date'\n",
    "    elif unique_count == length_count:\n",
    "        return 'text(unique)'\n",
    "    else :\n",
    "        return 'catagorical'\n",
    "def print_type(dataframe):\n",
    "    for columnname in dataframe.columns:\n",
    "        print(columnname + \":\" + get_catog(dataframe[columnname]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.ProfileReport(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLORATORY DATA ANALYSIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['amount_tsh', 'funder', 'gps_height',\n",
    " 'installer', 'basin', 'subvillage', 'population', 'public_meeting',\n",
    " 'scheme_management', 'scheme_name', 'permit', 'construction_year',\n",
    " 'extraction_type', 'payment_type', 'water_quality',   \n",
    " 'quantity_group', 'source_type', 'source_class', 'waterpoint_type',\n",
    " 'status_group']\n",
    "\n",
    "Eda_Data = pd.DataFrame(data[list],columns= list)\n",
    "\n",
    "\n",
    "Eda_Data['region'] = data['region']\n",
    "\n",
    "Eda_Data.head()\n",
    "\n",
    "temp = Eda_Data[(Eda_Data['status_group'] == 'functional needs repair') & (Eda_Data['amount_tsh'] != 0)]\n",
    "\n",
    "temp['amount_tsh'].min()\n",
    "\n",
    "Eda_Data['basin'].nunique()\n",
    "\n",
    "Eda_Data[\"status_group\"] = Eda_Data[\"status_group\"].apply(lambda x : \"func_Non_func\" if x in ['functional','non functional'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Eda_Data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functional_needs_repair = Eda_Data[Eda_Data['status_group'] == 'functional needs repair']\n",
    "\n",
    "temp = Eda_Data.groupby('waterpoint_type').agg({'status_group':\"count\"}).reset_index()\n",
    "\n",
    "temp\n",
    "\n",
    "### waterpoint_type_group\n",
    "mlt.figure(figsize = (10,5))\n",
    "plot1 = sns.countplot( x = 'waterpoint_type' , data =Eda_Data, dodge=False)\n",
    "mlt.title('waterpoint_type_group')\n",
    "mlt.savefig('C:/Users/kxj133/Downloads/plot1.png')\n",
    "\n",
    "## water_quality plot\n",
    "mlt.figure(figsize = (14,5))\n",
    "plot2 = sns.countplot( x = 'water_quality' , data =Eda_Data, hue = \"status_group\")\n",
    "mlt.title('water_quality')\n",
    "mlt.savefig('C:/Users/kxj133/Downloads/plot2.png')\n",
    "\n",
    "## quantity_group plot\n",
    "mlt.figure(figsize = (14,5))\n",
    "plot3 = sns.countplot( x = 'quantity_group' , data = Eda_Data, hue = \"status_group\")\n",
    "mlt.title('quantity_group')\n",
    "mlt.savefig('C:/Users/kxj133/Downloads/plot3.png')\n",
    "\n",
    "## basin comparison between functional and functional needs repair\n",
    "mlt.figure(figsize = (14,5))\n",
    "plot4 = sns.countplot( x = 'basin' , data = Eda_Data, hue = \"status_group\")\n",
    "mlt.title('basin comparison between functional and functional needs repair')\n",
    "mlt.savefig('C:/Users/kxj133/Downloads/plot4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "i =0\n",
    "\n",
    "for year in Eda_Data['construction_year']:\n",
    "    if year  in range(1960,1970):\n",
    "        list.append(\"1960-1969\")\n",
    "    elif year in range(1970,1980):\n",
    "        list.append(\"1970-1979\")\n",
    "    elif year in range(1980,1990):\n",
    "        list.append(\"1980-1989\")\n",
    "    elif year in range(1990,2000):\n",
    "        list.append(\"1990-1999\")\n",
    "    elif year in range(2000,2014):\n",
    "        list.append('2000-2013')\n",
    "    elif year == 0:\n",
    "        list.append(\"unknown\")\n",
    "        \n",
    "Eda_Data['construction_decade'] = list\n",
    "\n",
    "\n",
    "Eda_Data['construction_decade'].unique()\n",
    "\n",
    "\n",
    "Eda_Data['construction_year'].min(),Eda_Data['construction_year'].max()\n",
    "\n",
    "range(1960,1970)\n",
    "\n",
    "temp = Eda_Data.groupby([\"status_group\",\"region\"]).agg({'region':'count'}).sort_values(by = 'region')\n",
    "\n",
    "\n",
    "Eda_Data.region.value_counts().iloc[:15].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### comparison between functional and functional needs repair over region Chart\n",
    "mlt.figure(figsize = (25,10))\n",
    "plot4 = sns.countplot( x = 'region',data = Eda_Data, hue = \"status_group\",order=Eda_Data.region.value_counts().iloc[:9].index)\n",
    "mlt.title('comparison between functional and functional needs repair over region')\n",
    "mlt.savefig('C:/Users/kxj133/Downloads/plot4.png')\n",
    "\n",
    "## payment type for water pump chart\n",
    "mlt.figure(figsize = (15,8))\n",
    "plot4 = sns.countplot( x= \"payment_type\",data = Eda_Data,hue = \"status_group\" )\n",
    "mlt.title('payment type for water pump')\n",
    "mlt.savefig('C:/Users/kxj133/Downloads/plot5.png')\n",
    "\n",
    "\n",
    "Eda_Data['extraction_type'].value_counts()\n",
    "\n",
    "### Top 10 Extraction_type for water pump\n",
    "mlt.figure(figsize = (15,8))\n",
    "plot4 = sns.countplot( x= \"extraction_type\",data = Eda_Data,hue = \"status_group\",order = Eda_Data[\"extraction_type\"].value_counts().iloc[0:6].index)\n",
    "mlt.title('Top 10 Extraction_type for water pump')\n",
    "mlt.savefig('C:/Users/kxj133/Downloads/plot6.png')\n",
    "\n",
    "\n",
    "Eda_Data['permit'].value_counts()\n",
    "\n",
    "### chart on permitted and non-permitted water pump\n",
    "mlt.figure(figsize = (15,8))\n",
    "plot4 = sns.countplot( x= \"permit\",data = Eda_Data,hue = \"status_group\")\n",
    "mlt.title('chart on permitted and non-permitted water pump')\n",
    "mlt.savefig('C:/Users/kxj133/Downloads/plot7.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Choosing the one variable among three varaible since all has almost similiar information\n",
    "\n",
    "\n",
    "pd.Index(data['extraction_type']).difference(pd.Index(data['extraction_type_group'])).values\n",
    "\n",
    "pd.Index(data['extraction_type_group']).difference(pd.Index(data['extraction_type'])).values\n",
    "\n",
    "pd.Index(data['extraction_type_class']).difference(pd.Index(data['extraction_type'])).values\n",
    "\n",
    "print(data['extraction_type'].nunique(),data['extraction_type_group'].nunique(),data['extraction_type_class'].nunique())\n",
    "\n",
    "data['extraction_type_class'].isnull().sum()\n",
    "\n",
    "### Since Extraction_type_class variable has less class than other two variable , I am considering only\n",
    "#extraction_type_class variable\n",
    "\n",
    "data = data.drop([\"extraction_type\",\"extraction_type_group\"],axis = 1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the one variable between [\"quantity\",\"quantity_group\"] since all has almost similiar information\n",
    "\n",
    "data['quantity'].nunique(),data['quantity_group'].nunique() \n",
    "\n",
    "#Since both qunatity and quantity_group has same values removing one variable\n",
    "\n",
    "data = data.drop(['quantity_group'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Choosing the one variable between ['water_quanlity',''quality_group] since all has almost similiar information\n",
    "\n",
    "data['water_quality'].unique(),data['quality_group'].unique()\n",
    "\n",
    "#Since quality group variable has less class, i have retained this varaible\n",
    "data = data.drop(['water_quality'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choosing one variable among [\"source\",\"source_type\",\"source_class\"] since all varaible has almost similiar information\n",
    "\n",
    "data['source'].nunique(),data['source_type'].nunique(),data['source_class'].nunique()\n",
    "\n",
    "### Since source_type has no unknown value, i have retained \"Source_type\" Variable\n",
    "\n",
    "data = data.drop([\"source\",\"source_class\"],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### choosing one variable between[\"payment\",\"payment_type\"] since all variable has almost similiar information\n",
    "\n",
    "data['payment'].unique(),data['payment_type'].unique()\n",
    "\n",
    "data = data.drop(['payment'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data[data['num_private'] == 0].shape[0]/data.shape[0])\n",
    "\n",
    "##since 98 percent of observation has zero value, so it is useless variable\n",
    "\n",
    "data = data.drop(['num_private'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choosing one variable between ['management' , \"management_group\"]\n",
    "data['management'].unique(),data['management_group'].unique()\n",
    "\n",
    "### dropping management variable and retaining management_group variable\n",
    "data = data.drop(['management'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choosing one variable between['waterpoint_type',\"waterpoint_type_group\"]\n",
    "data['waterpoint_type'].unique(),data['waterpoint_type_group'].unique()\n",
    "\n",
    "### dropping \"waterpoint_type_group\" variable\n",
    "\n",
    "data = data.drop(['waterpoint_type'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since the recoreded_by varaible has only one class, it has no information. so, i dropped it\n",
    "data = data.drop(['recorded_by'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Since we have region varaible and subvillage varaible.so,i dropped longitude and latitude varaible\n",
    "\n",
    "data = data.drop(['longitude','latitude'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Since in Installer variable the string are mixed with lower and upper string converted everything into lower string\n",
    "data['funder'] = data['funder'].str.lower()\n",
    "data['installer'] = data['installer'].str.lower()\n",
    "\n",
    "## Retaining installer varaible \n",
    "\n",
    "print(data['funder'].nunique(),data['installer'].nunique())\n",
    "len(pd.Index(data['funder']).difference(pd.Index(data['installer'])).values.tolist()),len(pd.Index(data['installer']).difference(pd.Index(data['funder'])).values.tolist())\n",
    "\n",
    "data = data.drop(['funder'],axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### since the gps_height is having almost simiar distribution for both class in status group,\n",
    "##this variable will not be helpful for us to classify.so, i dropped this variable\n",
    "\n",
    "### Lets inspect gps_height \n",
    "sns.boxplot(x = 'status_group', y = 'gps_height',data = data)\n",
    "\n",
    "data = data.drop(['gps_height'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['amount_tsh'] == 0].shape[0]/data.shape[0] ## 70 % of Zero values\n",
    "\n",
    "## Lets inspect this variable by plotting boxplot\n",
    "temp = data[data['amount_tsh'] > 12000]\n",
    "sns.boxplot(x = 'status_group', y = 'amount_tsh', data = temp)\n",
    "\n",
    "##Since the the distribution of amount_tsh varaible is different for two different class of status group,i retained this variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[data['population'] >= 5000]\n",
    "sns.boxplot(x = 'status_group', y = 'population',data = temp) \n",
    "### since the distribution of population between status group is different. so, it will be helful to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['basin'].unique(),data['basin'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['usage_duration'] = pd.to_datetime(data['date_recorded']).dt.year - data['construction_year']\n",
    "\n",
    "temp = data[(data['construction_year'] != 0) & (data['construction_year'] <= pd.to_datetime(data['date_recorded']).dt.year )]\n",
    "temp.shape,data.shape\n",
    "\n",
    "temp_1 = data[(data['construction_year'] != 0)]\n",
    "temp_1.shape\n",
    "\n",
    "sns.boxplot(y =\"usage_duration\", x = \"status_group\",data = temp)\n",
    "\n",
    "### since the usage duration is also having the same disribution for both classes, I dropped the usage duration varaible,construction_year,recoreded_date\n",
    "data = data.drop(['usage_duration','construction_year','date_recorded'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Since we have region name i removed the region_code and district code\n",
    "data = data.drop(['region_code','district_code'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['wpt_name'].value_counts()\n",
    "\n",
    "dic = defaultdict(list)\n",
    "\n",
    "temp = pd.DataFrame(data.groupby(\"wpt_name\")['wpt_name'].count().sort_values(ascending  = False),index= None,columns = ['wpt_name'])\n",
    "temp['wpt_name'].items()\n",
    "for i,j in temp['wpt_name'].items():\n",
    "    #print(i)\n",
    "    #print(j)\n",
    "    if i== \"none\":\n",
    "        dic['wpt_name'].append(i)\n",
    "        dic['wpt_label'].append(\"wpt_none\")\n",
    "    elif j>=5 and i!= \"none\":\n",
    "        dic['wpt_name'].append(i)\n",
    "        dic['wpt_label'].append(\"wpt_high\")\n",
    "    elif j<5 and i!= \"none\" :\n",
    "        dic['wpt_name'].append(i)\n",
    "        dic['wpt_label'].append(\"wpt_less\")\n",
    "\n",
    "\n",
    "df = pd.DataFrame(dic)\n",
    "\n",
    "### Since we have around 37400 unique values we can't create dummy variables for all those classes so i grouped it into three groups based on the value counts\n",
    "## Those class which has more than 5 class are labelled as wpt_high and less than 5 as wpt_less and other as wpt_none\n",
    "#data['wpt_code'] = df['values']\n",
    "\n",
    "data = pd.merge(data,df,on = \"wpt_name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Since we have Wpt_label i removed Wpt_name variable\n",
    "data = data.drop([\"wpt_name\"],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['installer',\"subvillage\",\"region\",\"lga\",\"ward\",\"scheme_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.drop(['installer',\"subvillage\",\"region\",\"lga\",\"ward\",\"scheme_name\"],axis = 1)\n",
    "data = data.drop(['id'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,[0,1,2,3,4,5,6,7,8,9,10,11,12,14]]\n",
    "Y = data['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(class_weight= {\"functional needs repair\" : 0.9,\"func_Non_func\" : 0.1})\n",
    "train_x,test_x,train_y,test_y = train_test_split(X,Y,test_size = 0.30)\n",
    "model.fit(train_x,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(model.feature_importances_,X.columns,columns= ['values']).sort_values(by = \"values\",ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = pd.DataFrame(model_1.feature_importances_,X.columns,columns= ['values']).sort_values(by = \"values\",ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Imp_features = features.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_y,model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_y,model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(test_y,model.predict(test_x),pos_label=\"functional needs repair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model_1 = ExtraTreesClassifier(class_weight= {\"functional needs repair\" : 0.92,\"func_Non_func\" : 0.08})\n",
    "model_1.fit(train_x,train_y)\n",
    "accuracy_score(test_y,model_1.predict(test_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(test_y,model_1.predict(test_x),pos_label=\"functional needs repair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_y,model_1.predict(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['installer',\"subvillage\",\"region\",\"lga\",\"ward\",\"scheme_name\"]\n",
    "data[variables] = final_data[variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
